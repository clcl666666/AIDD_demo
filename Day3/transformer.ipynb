{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Understanding Python Classes and nn.Module\n",
    "Python Classes:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My dog's name is Buddy\n",
      "My dog's breed is Golden Retriever\n",
      "Buddy says Woof!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class Dog:\n",
    "    # The __init__ method is the constructor.\n",
    "    # It's called when you create a new object of this class.\n",
    "    def __init__(self, name, breed):\n",
    "        self.name = name  # Attribute 1\n",
    "        self.breed = breed # Attribute 2\n",
    "\n",
    "    # A method of the class\n",
    "    def bark(self):\n",
    "        print(f\"{self.name} says Woof!\")\n",
    "\n",
    "# Create an object (instance) of the Dog class\n",
    "my_dog = Dog(\"Buddy\", \"Golden Retriever\")\n",
    "\n",
    "# Access attributes\n",
    "print(f\"My dog's name is {my_dog.name}\")\n",
    "print(f\"My dog's breed is {my_dog.breed}\")\n",
    "\n",
    "# Call a method\n",
    "my_dog.bark()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67\n",
      "SimpleNN model structure:\n",
      "SimpleNN(\n",
      "  (fc1): Linear(in_features=10, out_features=5, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (fc2): Linear(in_features=5, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "Dummy input shape: torch.Size([1, 10])\n",
      "Output shape: torch.Size([1, 2])\n"
     ]
    }
   ],
   "source": [
    "# 了解nn.Module这个类的使用\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(SimpleNN, self).__init__() # Call the constructor of the parent class (nn.Module)\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size) # A linear layer\n",
    "        self.relu = nn.ReLU() # An activation function\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size) # Another linear layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Define the forward pass\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Example usage:\n",
    "input_size = 10\n",
    "hidden_size = 5\n",
    "output_size = 2\n",
    "\n",
    "# Create an instance of the SimpleNN module\n",
    "model = SimpleNN(input_size, hidden_size, output_size)\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(count_parameters(model))\n",
    "print(\"SimpleNN model structure:\")\n",
    "print(model)\n",
    "\n",
    "# Create some dummy input data\n",
    "dummy_input = torch.randn(1, input_size) # Batch size of 1\n",
    "\n",
    "# Pass the dummy input through the model\n",
    "output = model(dummy_input)\n",
    "\n",
    "print(\"\\nDummy input shape:\", dummy_input.shape)\n",
    "print(\"Output shape:\", output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn.Sequential —— 顺序执行的模块容器\n",
    "# import torch.nn as nn\n",
    "from collections import OrderedDict\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(10, 20),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(20, 1)\n",
    ")\n",
    "\n",
    "def forward(x):\n",
    "    x = Linear1(x)\n",
    "    x = ReLU(x)\n",
    "    x = Linear2(x)\n",
    "    return x\n",
    "\n",
    "# 或者你也可以显式命名：\n",
    "model = nn.Sequential(\n",
    "    OrderedDict([\n",
    "        ('fc1', nn.Linear(10, 20)),\n",
    "        ('relu', nn.ReLU()),\n",
    "        ('fc2', nn.Linear(20, 1))\n",
    "    ])\n",
    ")\n",
    "\n",
    "# 按顺序自动调用每一层的 forward()。\n",
    "# 不需要自己写 forward()。\n",
    "# 不适合复杂结构（比如需要跳连接、分支、合并的情况）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn.ModuleList —— 子模块列表\n",
    "# 用于保存一组子层，但不会自动执行它们。\n",
    "# 你需要手动在 forward() 中定义执行逻辑。\n",
    "import torch.nn as nn\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([\n",
    "            nn.Linear(10, 20),\n",
    "            nn.Linear(20, 30),\n",
    "            nn.Linear(30, 40)\n",
    "        ])\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:   # 手动循环\n",
    "            x = layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn.ModuleDict —— 带名字的模块字典\n",
    "# 用于保存带名称的模块集合（键值对形式），方便按名字访问。\n",
    "# 不自动执行，需要自己在 forward() 中指定调用哪些模块。\n",
    "# 常用于多分支网络、不同任务的共享骨干网络中。\n",
    "import torch.nn as nn\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.blocks = nn.ModuleDict({\n",
    "            'block1': nn.Linear(10, 20),\n",
    "            'block2': nn.Linear(20, 30)\n",
    "        })\n",
    "\n",
    "    def forward(self, x, use_block='block1'):\n",
    "        x = self.blocks[use_block](x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = nn.Linear(10,3)\n",
    "# print(p.numel) #返回张量里面总元素\n",
    "sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630\n",
      "torch.Size([128, 30])\n",
      "torch.Size([10, 128, 30])\n"
     ]
    }
   ],
   "source": [
    "# 全连接层，Linear层\n",
    "\n",
    "m = nn.Linear(20, 30)\n",
    "print(sum(p.numel() for p in m.parameters() if p.requires_grad))\n",
    "input = torch.randn(128, 20) # \n",
    "output = m(input)\n",
    "print(output.size()) #torch.Size([128, 30])\n",
    "\n",
    "input = torch.randn(10, 128, 20) # \n",
    "output = m(input)\n",
    "print(output.size()) #torch.Size([10, 128, 30])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = torch.rand(3,3)\n",
    "p.numel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe) # 注册缓存区，吧这个变量放入缓存区，使用更方便。\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "            x: Tensor, shape [seq_len, batch_size, embedding_dim]\n",
    "        \"\"\"\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return x\n",
    "\n",
    "# Example usage:\n",
    "d_model = 512  # Embedding dimension\n",
    "max_len = 100  # Maximum sequence length\n",
    "seq_len = 10   # Actual sequence length\n",
    "batch_size = 32\n",
    "\n",
    "# Create a dummy input tensor (representing embeddings)\n",
    "input_embeddings = torch.randn(seq_len, batch_size, d_model)\n",
    "# 快速验证模型的前向传播（forward pass）是否能够正常执行，而无需准备真实的数据集。这有助于检查模型结构是否正确、是否存在维度不匹配等问题\n",
    "# Create a PositionalEncoding layer\n",
    "pos_encoder = PositionalEncoding(d_model, max_len)\n",
    "\n",
    "# Add positional encoding to the input embeddings\n",
    "output_with_pos = pos_encoder(input_embeddings)\n",
    "\n",
    "print(\"Input embeddings shape:\", input_embeddings.shape)\n",
    "print(\"Output with positional encoding shape:\", output_with_pos.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "# LayerNorm: normalized_shape参数指定要归一化的特征维度\n",
    "self.ln = nn.LayerNorm(hidden_size)  # 参数是特征维度\n",
    "# 前向传播 (Pre-Norm示例)\n",
    "x = x + self.attention(self.ln(x))  # 残差连接 + 注意力 + LayerNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "attn = nn.MultiheadAttention(embed_dim=512, num_heads=8)\n",
    "output, weights = attn(query, key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn = nn.MultiheadAttention(embed_dim=512, num_heads=8)\n",
    "### query is antibody\n",
    "k = self.pos(ab_seq)\n",
    "q = self.pos(ag_seq)\n",
    "seq_out,attention = attn2(q, k, value=k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attn_output shape: torch.Size([6, 2, 512])\n",
      "attn_weights shape: torch.Size([2, 6, 10])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 假设参数\n",
    "embed_dim = 512\n",
    "num_heads = 8\n",
    "batch_size = 2\n",
    "src_len = 10    # encoder输出序列长度\n",
    "tgt_len = 6     # decoder当前序列长度\n",
    "\n",
    "# 初始化注意力层\n",
    "attn = nn.MultiheadAttention(embed_dim=embed_dim, num_heads=num_heads, batch_first=False)\n",
    "\n",
    "# 模拟 encoder 输出 (K, V)\n",
    "encoder_output = torch.randn(src_len, batch_size, embed_dim)\n",
    "\n",
    "# 模拟 decoder 当前层输入 (Q)\n",
    "decoder_hidden = torch.randn(tgt_len, batch_size, embed_dim)\n",
    "\n",
    "# 执行交叉注意力\n",
    "attn_output, attn_weights = attn(\n",
    "    query=decoder_hidden,  # Q ← decoder\n",
    "    key=encoder_output,    # K ← encoder\n",
    "    value=encoder_output   # V ← encoder\n",
    ")\n",
    "\n",
    "print(\"attn_output shape:\", attn_output.shape)\n",
    "print(\"attn_weights shape:\", attn_weights.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feed Forward层（前馈神经网络层）\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, embed_dim=512, hidden_dim=2048, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(embed_dim, hidden_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear2 = nn.Linear(hidden_dim, embed_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = F.relu(x)   # 或 F.gelu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.linear2(x)\n",
    "        return x\n",
    "\n",
    "# 示例\n",
    "ffn = FeedForward()\n",
    "x = torch.randn(10, 32, 512)  # (seq_len, batch_size, embed_dim)\n",
    "y = ffn(x)\n",
    "print(y.shape)  # torch.Size([10, 32, 512])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python实现\n",
    "import numpy as np\n",
    "\n",
    "def softmax(x):\n",
    "    exp_x = np.exp(x - np.max(x))  # 数值稳定：减最大值\n",
    "    return exp_x / np.sum(exp_x)\n",
    "\n",
    "x = np.array([2.0, 1.0, 0.1])\n",
    "print(softmax(x))  # [0.65900114 0.24243297 0.09856589]\n",
    "\n",
    "# Pytorch实现\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "x = torch.tensor([2.0, 1.0, 0.1])\n",
    "output = F.softmax(x, dim=0)\n",
    "print(output)  # tensor([0.6590, 0.2424, 0.0986])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len).unsqueeze(1).float()\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * \n",
    "                           -(math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe.unsqueeze(0))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:, :x.size(1)]\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, nhead):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.nhead = nhead\n",
    "        self.d_k = d_model // nhead\n",
    "        self.W_Q = nn.Linear(d_model, d_model)\n",
    "        self.W_K = nn.Linear(d_model, d_model)\n",
    "        self.W_V = nn.Linear(d_model, d_model)\n",
    "        self.W_O = nn.Linear(d_model, d_model)\n",
    "    \n",
    "    def forward(self, Q, K, V, mask=None):\n",
    "        batch_size = Q.size(0)\n",
    "        Q = self.W_Q(Q).view(batch_size, -1, self.nhead, self.d_k).transpose(1, 2)\n",
    "        K = self.W_K(K).view(batch_size, -1, self.nhead, self.d_k).transpose(1, 2)\n",
    "        V = self.W_V(V).view(batch_size, -1, self.nhead, self.d_k).transpose(1, 2)\n",
    "        \n",
    "        scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.d_k)\n",
    "        if mask is not None:\n",
    "            scores = scores.masked_fill(mask == 0, -1e9)\n",
    "        attn = F.softmax(scores, dim=-1)\n",
    "        context = torch.matmul(attn, V)\n",
    "        context = context.transpose(1, 2).contiguous().view(batch_size, -1, self.d_model)\n",
    "        return self.W_O(context), attn\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff=2048):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(d_model, d_ff)\n",
    "        self.linear2 = nn.Linear(d_ff, d_model)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.linear2(F.relu(self.linear1(x)))\n",
    "\n",
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, nhead):\n",
    "        super().__init__()\n",
    "        self.self_attn = MultiHeadAttention(d_model, nhead)\n",
    "        self.ffn = FeedForward(d_model)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # 自注意力 + 残差\n",
    "        attn_out, _ = self.self_attn(x, x, x)\n",
    "        x = self.norm1(x + attn_out)\n",
    "        # 前馈 + 残差\n",
    "        ffn_out = self.ffn(x)\n",
    "        x = self.norm2(x + ffn_out)\n",
    "        return x\n",
    "\n",
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, nhead):\n",
    "        super().__init__()\n",
    "        self.self_attn = MultiHeadAttention(d_model, nhead)\n",
    "        self.enc_dec_attn = MultiHeadAttention(d_model, nhead)\n",
    "        self.ffn = FeedForward(d_model)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.norm3 = nn.LayerNorm(d_model)\n",
    "    \n",
    "    def forward(self, x, enc_out, src_mask=None, tgt_mask=None):\n",
    "        # 掩码自注意力 + 残差\n",
    "        attn_out, _ = self.self_attn(x, x, x, tgt_mask)\n",
    "        x = self.norm1(x + attn_out)\n",
    "        # 编码器-解码器注意力 + 残差\n",
    "        attn_out, _ = self.enc_dec_attn(x, enc_out, enc_out, src_mask)\n",
    "        x = self.norm2(x + attn_out)\n",
    "        # 前馈 + 残差\n",
    "        ffn_out = self.ffn(x)\n",
    "        x = self.norm3(x + ffn_out)\n",
    "        return x\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, src_vocab_size, tgt_vocab_size, d_model=512, nhead=8, num_layers=6):\n",
    "        super().__init__()\n",
    "        self.src_embedding = nn.Embedding(src_vocab_size, d_model)\n",
    "        self.tgt_embedding = nn.Embedding(tgt_vocab_size, d_model)\n",
    "        self.pos_enc = PositionalEncoding(d_model)\n",
    "        self.encoder_layers = nn.ModuleList([\n",
    "            EncoderLayer(d_model, nhead) for _ in range(num_layers)\n",
    "        ])\n",
    "        self.decoder_layers = nn.ModuleList([\n",
    "            DecoderLayer(d_model, nhead) for _ in range(num_layers)\n",
    "        ])\n",
    "        self.fc_out = nn.Linear(d_model, tgt_vocab_size)\n",
    "    \n",
    "    def forward(self, src, tgt, src_mask=None, tgt_mask=None):\n",
    "        # 编码器\n",
    "        src_emb = self.pos_enc(self.src_embedding(src)) * math.sqrt(self.src_embedding.embedding_dim)\n",
    "        enc_out = src_emb\n",
    "        for layer in self.encoder_layers:\n",
    "            enc_out = layer(enc_out)\n",
    "        \n",
    "        # 解码器\n",
    "        tgt_emb = self.pos_enc(self.tgt_embedding(tgt)) * math.sqrt(self.tgt_embedding.embedding_dim)\n",
    "        dec_out = tgt_emb\n",
    "        for layer in self.decoder_layers:\n",
    "            dec_out = layer(dec_out, enc_out, src_mask, tgt_mask)\n",
    "        \n",
    "        return self.fc_out(dec_out)\n",
    "\n",
    "# 使用示例\n",
    "model = Transformer(src_vocab_size=10000, tgt_vocab_size=10000)\n",
    "src = torch.randint(0, 10000, (32, 10))  # batch=32, src_len=10\n",
    "tgt = torch.randint(0, 10000, (32, 12))  # tgt_len=12\n",
    "output = model(src, tgt)\n",
    "print(output.shape)  # [32, 12, 10000]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
