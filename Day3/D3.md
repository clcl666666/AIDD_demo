1.	基础知识讲解
    1)	介绍蛋白质的语言模型（26字母语言模型->20氨基酸字母表，上下文依赖->氨基酸的共进化）
    2)	为什么要开发蛋白质大语言模型？1. 相比于结构或功能信息，序列信息更加海量；2. 蛋白质序列通过进化而来，可以学习蛋白质基本规律，折叠，共进化等
    3)	模型架构和基础理论：transformer，多头注意力机制，Bert，GPT，T5等
2.	基于Bert架构的蛋白质语言模型
    1)	ESM系列（ESM-1b、ESM-1v、ESM2、ESM C）
    2)	ESMFold：无需MSA信息的结构预测
    3)	使用抗体序列库训练的语言模型：Ablang，AntiBERTy
3.	类似GPT的生成模型ProGen
    1)	36层Transformer解码器架构，包含12亿参数
    2)	引入“控制标签”（如蛋白质家族ID、功能属性）作为输入，生成蛋白质序列空间以外的新的蛋白质序列
    3)	成功生成新的溶菌酶
4.	多模态的蛋白质语言模型ESM3
    1)	模型架构融合序列，结构和功能信息
    2)	相比于ESMFold，单体结构预测精度更好
    3)	基于多模态提示（序列、结构、功能关键词）设计新的蛋白质序列
    4)	ESM3的安装，生成序列，快速结构预测。*
 
5.	蛋白质语言模型的应用和实战演练*
    1)	获得序列embedding以构建下游模型（Cell systmes文章举例），从文章github仓库中提炼序列embedding的代码并学习使用。https://github.com/fhalab/MLDE?tab=readme-ov-file#generating-encodings-with-generate_encoding.py，看懂代码中EncodingGenerator的类，将这个类方法用在我们自己的代码上，实现蛋白质序列的不同方式encoding，包括"onehot", "georgiev", “esm”系列模型。
    2)	使用不同的蛋白质语言模型，零样本的预测蛋白质突变效应。
    3)	给定少量的突变效应数据作为训练数据，训练模型，预测新的突变效应值。


两个大的代码：

零样本预测
少量数据训练。(这里包含获得序列embedding)